[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "“Data Wow” purports to be an engaging and insightful blog at the crossroads of data science, statistics, and technology. Authored by a passionate university professor with expertise in biostatistics, data science, psychometrics, and engineering, this blog delves deep into the world of data analytics and machine learning. Through a blend of casual and formal discourse, it offers a unique perspective on harnessing the power of data to uncover fascinating insights, solve real-world problems, and advocate for equal opportunity and fairness in higher education—a fun-read for data enthusiasts and advocates of data-driven decision-making."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Wow",
    "section": "",
    "text": "Dummy Coding vs. Effects Coding\n\n\n\n\n\n\n\nTeaching\n\n\nRegression\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2023\n\n\nDavood Tofighi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-09-16-my-first-post/index.html",
    "href": "posts/2023-09-16-my-first-post/index.html",
    "title": "Dummy Coding vs. Effects Coding",
    "section": "",
    "text": "Going Beyond the Basics: Understanding Dummy Coding vs. Effects Coding in the General Linear Model\nHey there, fellow data enthusiasts! Today, I want to dive into the fascinating world of statistical modeling and explore the differences between two popular coding methods: dummy coding and effects coding in the general linear model (GLM). If you’ve ever wondered how to effectively represent categorical variables in your models, this blog post is for you!\nLet’s start by clarifying what dummy coding and effects coding actually are. In essence, both methods are used to represent categorical variables with multiple levels in regression models. They provide a way to quantify and incorporate the influence of different categories into our statistical analyses.\nNow, you might be wondering why exactly we need to code our categorical variables. Well, it all comes down to the fact that most statistical models, including the GLM, require numeric inputs. Dummy coding and effects coding help us transform our qualitative data into a quantitative format that can be easily understood by the model.\nFirst, let’s talk about dummy coding. This method involves creating a set of binary variables, often referred to as “dummy variables,” to represent the different levels of a categorical variable. Each level is assigned a 1 or 0, indicating its presence or absence. This approach is simple and intuitive, making it a popular choice for many researchers.\nFor example, let’s say we have a variable with three categories: A, B, and C. By using dummy coding, we would create two binary variables: one for B and another for C. Category A serves as the reference level, so it doesn’t need its own dummy variable. The model then estimates the influence of B and C relative to A.\nOn the other hand, effects coding, also known as deviation coding or sum-to-zero coding, takes a slightly different approach. Instead of using 1s and 0s, effects coding assigns values of -1, 0, and 1 to the different levels of the categorical variable. This coding scheme allows us to estimate the average effect of each category relative to the overall mean.\nUsing the same example, with effects coding, we would assign a value of -1 to category A, 0 to category B, and 1 to category C. The sum of these values equals zero, capturing the average effect of the categorical variable.\nSo, which coding method should you choose? Well, it depends on the research question and the hypotheses you want to test. Dummy coding is often favored when we are primarily interested in comparing each category to a reference level. It provides straightforward interpretation and facilitates hypothesis testing.\nFor instance, if our model using dummy coding returns a coefficient of 0.5 for category B, it means that category B has a 0.5 unit increase in the outcome variable compared to the reference category A. Similarly, a coefficient of -0.3 for category C indicates a 0.3 unit decrease in the outcome variable compared to category A.\nEffects coding, on the other hand, is useful when we want to examine the average effect of each category relative to the overall mean. In this coding scheme, the coefficients represent the difference between the category and the average of all categories.\nFor example, if our effects coding model returns a coefficient of -0.2 for category A, it means that category A has a 0.2 unit decrease in the outcome variable compared to the overall mean. Similarly, a coefficient of 0.4 for category C indicates a 0.4 unit increase in the outcome variable compared to the overall mean.\nIn conclusion, both dummy coding and effects coding offer valuable ways to represent categorical variables in the general linear model. Whether you choose one over the other depends on the specific goals of your analysis. Remember, coding is just one piece of the puzzle when it comes to statistical modeling. It’s important to consider other factors such as sample size, variable selection, and model assumptions to ensure accurate and meaningful results.\nI hope this blog post has shed some light on the differences between dummy coding and effects coding in the GLM. As always, keep exploring, keep learning, and keep unraveling the mysteries of data!\nUntil next time,\nDavood"
  }
]